package openai

import (
	"fmt"
	"strings"
)

// ModelProvider å®šä¹‰æ¨¡å‹æä¾›å•†
type ModelProvider string

const (
	ProviderOpenAI     ModelProvider = "openai"
	ProviderAnthropic  ModelProvider = "anthropic"
	ProviderQwen       ModelProvider = "qwen"
	ProviderGoogle     ModelProvider = "google"
	ProviderDeepSeek   ModelProvider = "deepseek"
	ProviderMoonshot   ModelProvider = "moonshot"
)

// ModelInfo æ¨¡å‹ä¿¡æ¯ç»“æ„
type ModelInfo struct {
	ID           string        `json:"id"`           // æ¨¡å‹ID (å¦‚: openai/gpt-4o)
	Name         string        `json:"name"`         // æ˜¾ç¤ºåç§° (å¦‚: GPT-4o)
	Provider     ModelProvider `json:"provider"`     // æä¾›å•†
	Description  string        `json:"description"`  // æ¨¡å‹æè¿°
	MaxTokens    int          `json:"max_tokens"`   // æœ€å¤§tokenæ•°
	IsFree       bool         `json:"is_free"`      // æ˜¯å¦å…è´¹
	Capabilities []string     `json:"capabilities"` // èƒ½åŠ›åˆ—è¡¨ (text, image, visionç­‰)
	Category     string       `json:"category"`     // åˆ†ç±» (é€šç”¨, ç¼–ç¨‹, ä¸“ä¸šç­‰)
}

// æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
var SupportedModels = map[string]*ModelInfo{
	"openai/gpt-4o": {
		ID:           "openai/gpt-4o",
		Name:         "GPT-4o",
		Provider:     ProviderOpenAI,
		Description:  "OpenAIæœ€æ–°çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒå’Œè¯­éŸ³",
		MaxTokens:    128000,
		IsFree:       false,
		Capabilities: []string{"text", "vision", "reasoning"},
		Category:     "é€šç”¨",
	},
	"openai/gpt-4.1": {
		ID:           "openai/gpt-4.1",
		Name:         "GPT-4.1",
		Provider:     ProviderOpenAI,
		Description:  "OpenAI GPT-4.1ï¼Œå¢å¼ºçš„æ¨ç†èƒ½åŠ›",
		MaxTokens:    128000,
		IsFree:       false,
		Capabilities: []string{"text", "reasoning"},
		Category:     "é€šç”¨",
	},
	"qwen/qwen3-coder:free": {
		ID:           "qwen/qwen3-coder:free",
		Name:         "Qwen3 Coder (å…è´¹)",
		Provider:     ProviderQwen,
		Description:  "é€šä¹‰åƒé—®3ä»£ç ä¸“å®¶ç‰ˆï¼Œä¸“ä¸ºç¼–ç¨‹ä»»åŠ¡ä¼˜åŒ–",
		MaxTokens:    32768,
		IsFree:       true,
		Capabilities: []string{"text", "coding"},
		Category:     "ç¼–ç¨‹",
	},
	"google/gemini-2.5-pro": {
		ID:           "google/gemini-2.5-pro",
		Name:         "Gemini 2.5 Pro",
		Provider:     ProviderGoogle,
		Description:  "Googleæœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ€§èƒ½å“è¶Š",
		MaxTokens:    1000000,
		IsFree:       false,
		Capabilities: []string{"text", "vision", "reasoning"},
		Category:     "é€šç”¨",
	},
	"anthropic/claude-sonnet-4": {
		ID:           "anthropic/claude-sonnet-4",
		Name:         "claude-sonnet-4",
		Provider:     ProviderAnthropic,
		Description:  "Anthropicæœ€æ–°çš„Claudeæ¨¡å‹ï¼Œæ“…é•¿åˆ†æå’Œæ¨ç†",
		MaxTokens:    200000,
		IsFree:       false,
		Capabilities: []string{"text", "analysis", "reasoning"},
		Category:     "åˆ†æ",
	},
	"deepseek/deepseek-chat-v3-0324:free": {
		ID:           "deepseek/deepseek-chat-v3-0324:free",
		Name:         "DeepSeek Chat V3 (å…è´¹)",
		Provider:     ProviderDeepSeek,
		Description:  "æ·±åº¦æ±‚ç´¢èŠå¤©æ¨¡å‹V3ç‰ˆæœ¬ï¼Œå…è´¹ä½¿ç”¨",
		MaxTokens:    32768,
		IsFree:       true,
		Capabilities: []string{"text", "reasoning"},
		Category:     "é€šç”¨",
	},
	"moonshot/kimi-k2-0711-preview": {
		ID:           "moonshot/kimi-k2-0711-preview",
		Name:         "Kimi K2 (å…è´¹)",
		Provider:     ProviderMoonshot,
		Description:  "æœˆä¹‹æš—é¢Kimi K2æ¨¡å‹ï¼ŒOpenRouterå…è´¹ç‰ˆæœ¬",
		MaxTokens:    128000,
		IsFree:       true,
		Capabilities: []string{"text", "long_context", "reasoning"},
		Category:     "é•¿æ–‡æœ¬",
	},
}

// ModelCategory æ¨¡å‹åˆ†ç±»
var ModelCategories = map[string][]string{
	"é€šç”¨": {
		"openai/gpt-4o",
		"openai/gpt-4.1", 
		"google/gemini-2.5-pro",
		"deepseek/deepseek-chat-v3-0324:free",
	},
	"ç¼–ç¨‹": {
		"qwen/qwen3-coder:free",
	},
	"åˆ†æ": {
		"anthropic/claude-sonnet-4",
	},
	"é•¿æ–‡æœ¬": {
		"moonshot/kimi-k2-0711-preview",
	},
	"å…è´¹": {
		"qwen/qwen3-coder:free",
		"deepseek/deepseek-chat-v3-0324:free",
		"moonshot/kimi-k2-0711-preview",
	},
}

// GetModelInfo è·å–æ¨¡å‹ä¿¡æ¯
func GetModelInfo(modelID string) (*ModelInfo, bool) {
	model, exists := SupportedModels[modelID]
	return model, exists
}

// GetModelsByCategory æŒ‰åˆ†ç±»è·å–æ¨¡å‹
func GetModelsByCategory(category string) []*ModelInfo {
	var models []*ModelInfo
	if modelIDs, exists := ModelCategories[category]; exists {
		for _, modelID := range modelIDs {
			if model, ok := SupportedModels[modelID]; ok {
				models = append(models, model)
			}
		}
	}
	return models
}

// GetAllModels è·å–æ‰€æœ‰æ¨¡å‹
func GetAllModels() []*ModelInfo {
	var models []*ModelInfo
	for _, model := range SupportedModels {
		models = append(models, model)
	}
	return models
}

// GetFreeModels è·å–å…è´¹æ¨¡å‹
func GetFreeModels() []*ModelInfo {
	var models []*ModelInfo
	for _, model := range SupportedModels {
		if model.IsFree {
			models = append(models, model)
		}
	}
	return models
}

// SearchModels æœç´¢æ¨¡å‹
func SearchModels(keyword string) []*ModelInfo {
	var models []*ModelInfo
	keyword = strings.ToLower(keyword)
	
	for _, model := range SupportedModels {
		if strings.Contains(strings.ToLower(model.Name), keyword) ||
		   strings.Contains(strings.ToLower(model.Description), keyword) ||
		   strings.Contains(strings.ToLower(string(model.Provider)), keyword) {
			models = append(models, model)
		}
	}
	return models
}

// GetModelDisplayText è·å–æ¨¡å‹æ˜¾ç¤ºæ–‡æœ¬
func GetModelDisplayText(modelID string) string {
	if model, exists := SupportedModels[modelID]; exists {
		freeTag := ""
		if model.IsFree {
			freeTag = " ğŸ†“"
		}
		return fmt.Sprintf("%s%s - %s", model.Name, freeTag, model.Description)
	}
	return modelID
}

// ValidateModel éªŒè¯æ¨¡å‹æ˜¯å¦æ”¯æŒ
func ValidateModel(modelID string) error {
	if _, exists := SupportedModels[modelID]; !exists {
		return fmt.Errorf("ä¸æ”¯æŒçš„æ¨¡å‹: %s", modelID)
	}
	return nil
}

// DefaultModel é»˜è®¤æ¨¡å‹
const DefaultModel = "openai/gpt-4o"

// GetDefaultModel è·å–é»˜è®¤æ¨¡å‹
func GetDefaultModel() string {
	return DefaultModel
}